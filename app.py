# app.py
# ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º Ã— é»„é‡‘æ¯”/ç™½éŠ€æ¯”ï¼ˆå›è»¢è£œæ­£ â†’ é¡”ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã«æç”»ï¼‰
# ãƒ»é¡”ã‚’ç›®ã®æ°´å¹³ã§å›è»¢è£œæ­£
# ãƒ»é¡”å¤–å‘¨ã‹ã‚‰ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆä½™ç™½ã‚ã‚Šï¼‰
# ãƒ»é»„é‡‘æ¯”(Ï†) / ç™½éŠ€æ¯”(âˆš2) ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’2æšä½œæˆã—ã€UIã§åˆ‡ã‚Šæ›¿ãˆ
# ãƒ»ä¸‰åˆ†å‰²ã¯ã€Œçœ‰ â†” é¼»ä¸‹ã€åŒºé–“ã‚’1/3ç­‰åˆ†åŸºæº–ï¼ˆç†æƒ³ï¼‰ã§è¡¨ç¤º
# ãƒ»è¡¨ã«ã€Œé¡”H/Wã€ã€Œçœ‰â†”é¼»ä¸‹ã®ä¸‰åˆ†å‰²ã€ã€Œç›®é–“éš”/ç‰‡ç›®å¹…ã€ã€Œé¼»å¹…/å£å¹…ã€ã‚’è¡¨ç¤º
# â€»Streamlit 1.46ç³»ã€mediapipe 0.10ç³»ã€opencv-python-headless ã§å‹•ä½œæƒ³å®š

import math
from typing import Dict, Tuple, List
import cv2
import numpy as np
import streamlit as st
from PIL import Image
import mediapipe as mp
from mediapipe.framework.formats import landmark_pb2 as mp_landmark
import pandas as pd

# -------------------- ãƒšãƒ¼ã‚¸è¨­å®š --------------------
st.set_page_config(page_title="é¡” Ã— é»„é‡‘æ¯”/ç™½éŠ€æ¯” æ¯”è¼ƒ", page_icon="ğŸ“", layout="centered")
st.markdown("<style>#MainMenu,header,footer{visibility:hidden;}</style>", unsafe_allow_html=True)
st.title("ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º Ã— é»„é‡‘æ¯” / ç™½éŠ€æ¯”")

st.caption(
    "é¡”ã‚’è‡ªå‹•ã§æ°´å¹³ã«è£œæ­£ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã€é»„é‡‘æ¯”(Ï†â‰ˆ1.618) / ç™½éŠ€æ¯”(âˆš2â‰ˆ1.414)ã®ç†æƒ³æ ã¨ã€"
    "ã€Œçœ‰ â†” é¼»ä¸‹ã€ã®ä¸‰åˆ†å‰²ï¼ˆ1/3ç­‰åˆ†ï¼‰ã‚’é‡ã­ã¦æ¯”è¼ƒã—ã¾ã™ã€‚"
)

# -------------------- MediaPipe åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ --------------------
@st.cache_resource
def get_facemesh():
    return mp.solutions.face_mesh.FaceMesh(
        static_image_mode=True,
        refine_landmarks=True,
        max_num_faces=1,
        min_detection_confidence=0.3
    )

mp_face = mp.solutions.face_mesh
mp_draw = mp.solutions.drawing_utils
face_mesh = get_facemesh()

# -------------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ --------------------
def pil2np(img: Image.Image) -> np.ndarray:
    return np.array(img.convert("RGB"))

def dist(p1, p2) -> float:
    return float(np.linalg.norm(np.array(p1) - np.array(p2)))

def landmarks_to_xy(landmarks, w: int, h: int) -> np.ndarray:
    return np.array([(lm.x * w, lm.y * h) for lm in landmarks], dtype=np.float32)

def face_oval_indices() -> List[int]:
    return sorted({i for pair in mp_face.FACEMESH_FACE_OVAL for i in pair})

def dashed_line(img, pt1, pt2, color, thickness=2, dash=12, gap=8):
    """OpenCV ã§ç ´ç·šï¼ˆã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
    p1 = np.array(pt1, dtype=float); p2 = np.array(pt2, dtype=float)
    length = np.linalg.norm(p2 - p1)
    if length < 1: return
    v = (p2 - p1) / length
    n = int(length // (dash + gap)) + 1
    for i in range(n):
        s = p1 + (dash + gap) * i * v
        e = p1 + ((dash + gap) * i + dash) * v
        cv2.line(img, tuple(s.astype(int)), tuple(e.astype(int)), color, thickness, lineType=cv2.LINE_AA)

# -------------------- ä»£è¡¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆMediaPipe idxï¼‰ --------------------
IDX = dict(
    R_E_OUT=33,   # å³ç›® å¤–å´
    R_E_IN=133,   # å³ç›® å†…å´
    L_E_IN=362,   # å·¦ç›® å†…å´
    L_E_OUT=263,  # å·¦ç›® å¤–å´
    M_R=61,       # å£ å³
    M_L=291,      # å£ å·¦
    NOSE_L=97,    # é¼»ç¿¼ å·¦ç«¯ è¿‘ä¼¼
    NOSE_R=326,   # é¼»ç¿¼ å³ç«¯ è¿‘ä¼¼
    CHIN=152,     # é¡ å…ˆç«¯
    FOREHEAD=10,  # é¡ä¸Šéƒ¨ è¿‘ä¼¼ï¼ˆé«ªéš›ã§ã¯ãªã„ï¼‰
    BROW_R_UP=105,# å³çœ‰ ä¸Šæ–¹ã®ç‚¹
    BROW_L_UP=334,# å·¦çœ‰ ä¸Šæ–¹ã®ç‚¹
)

# -------------------- æŒ‡æ¨™è¨ˆç®—ï¼ˆâ€»ä¸‰åˆ†å‰²ã¯ã€Œçœ‰ â†” é¼»ä¸‹ã€åŒºé–“ï¼‰ --------------------
def compute_metrics(xy: np.ndarray) -> Dict[str, float]:
    # é¡”å¤–å‘¨ï¼ˆå¹…ãƒ»é«˜ã•ãƒ»H/Wï¼‰
    oval = face_oval_indices()
    pts = xy[oval]
    left  = tuple(pts[pts[:,0].argmin()])
    right = tuple(pts[pts[:,0].argmax()])
    top   = tuple(pts[pts[:,1].argmin()])
    bottom= tuple(pts[pts[:,1].argmax()])
    face_w = dist(left, right)
    face_h = dist(top, bottom)
    face_AR = face_h / face_w if face_w > 1e-6 else np.nan

    # ç›®ï¼šå¹…ï¼ä¸­å¿ƒé–“éš”
    re_w = dist(xy[IDX["R_E_OUT"]], xy[IDX["R_E_IN"]])
    le_w = dist(xy[IDX["L_E_OUT"]], xy[IDX["L_E_IN"]])
    eye_w = (re_w + le_w) / 2.0
    re_c = (xy[IDX["R_E_OUT"]] + xy[IDX["R_E_IN"]]) / 2.0
    le_c = (xy[IDX["L_E_OUT"]] + xy[IDX["L_E_IN"]]) / 2.0
    interocular = dist(re_c, le_c)
    eye_spacing_ratio = interocular / eye_w if eye_w > 1e-6 else np.nan

    # é¼»å¹… / å£å¹…ï¼ˆè¦ä»¶ã«åˆã‚ã›ã€Œé¼»å¹…/å£å¹…ã€ï¼‰
    nose_w  = dist(xy[IDX["NOSE_L"]], xy[IDX["NOSE_R"]])
    mouth_w = dist(xy[IDX["M_R"]],   xy[IDX["M_L"]])
    nose_to_mouth = nose_w / mouth_w if mouth_w > 1e-6 else np.nan

    # ä¸‰åˆ†å‰²ã®åŒºé–“ç«¯ï¼šçœ‰ãƒ©ã‚¤ãƒ³ï¼ˆå·¦å³çœ‰ä¸Šã®å¹³å‡yï¼‰â†” é¼»ä¸‹ï¼ˆé¼»ç¿¼å·¦å³ã®å¹³å‡yï¼‰
    brow_y = (xy[IDX["BROW_R_UP"]][1] + xy[IDX["BROW_L_UP"]][1]) / 2.0
    nose_base_y = (xy[IDX["NOSE_L"]][1] + xy[IDX["NOSE_R"]][1]) / 2.0
    segment_h = (nose_base_y - brow_y)  # ä¸‹å‘ããŒ+ï¼ˆç”»åƒåº§æ¨™ï¼‰

    return dict(
        face_w=face_w, face_h=face_h, face_AR=face_AR,
        eye_spacing_ratio=eye_spacing_ratio,
        nose_to_mouth=nose_to_mouth,
        brow_y=brow_y, nose_base_y=nose_base_y, segment_h=segment_h
    )

# -------------------- å›è»¢è£œæ­£ & é¡”ãƒˆãƒªãƒŸãƒ³ã‚° --------------------
def align_and_crop(img_rgb: np.ndarray, xy: np.ndarray, margin=0.18) -> Tuple[np.ndarray, np.ndarray]:
    """ç›®ã®æ°´å¹³ã§å›è»¢â†’å¤–å‘¨BBoxã§åˆ‡ã‚Šå‡ºã—ï¼ˆä½™ç™½ã‚ã‚Šï¼‰â†’åº§æ¨™ã‚‚å¤‰æ›"""
    h, w, _ = img_rgb.shape
    # ç›®ã®ä¸­å¿ƒã§è§’åº¦
    re_c = (xy[IDX["R_E_OUT"]] + xy[IDX["R_E_IN"]]) / 2.0
    le_c = (xy[IDX["L_E_OUT"]] + xy[IDX["L_E_IN"]]) / 2.0
    dy, dx = (le_c[1] - re_c[1]), (le_c[0] - re_c[0])
    angle_deg = math.degrees(math.atan2(dy, dx))
    center = (w/2.0, h/2.0)

    # ç”»åƒå›è»¢
    M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)
    rot = cv2.warpAffine(img_rgb, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)

    # ç‚¹ç¾¤å›è»¢
    ones = np.ones((xy.shape[0], 1))
    xy_h = np.hstack([xy, ones])
    xy_rot = (M @ xy_h.T).T  # (N,2)

    # é¡”å¤–å‘¨ã‹ã‚‰BBox
    oval = face_oval_indices()
    pts = xy_rot[oval]
    x1, y1 = np.min(pts, axis=0)
    x2, y2 = np.max(pts, axis=0)
    # ä½™ç™½
    w0, h0 = x2-x1, y2-y1
    x1 -= w0*margin; x2 += w0*margin
    y1 -= h0*margin; y2 += h0*margin
    x1 = int(max(0, x1)); y1 = int(max(0, y1))
    x2 = int(min(w-1, x2)); y2 = int(min(h-1, y2))

    crop = rot[y1:y2, x1:x2].copy()
    xy_crop = xy_rot.copy()
    xy_crop[:,0] -= x1; xy_crop[:,1] -= y1
    return crop, xy_crop

# -------------------- ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆcropå¾Œã«æç”»ï¼‰ --------------------
PHI = (1 + 5**0.5) / 2.0
SILVER = 2 ** 0.5

def build_overlay(crop: np.ndarray, xy: np.ndarray, target_ratio: float, label: str) -> np.ndarray:
    """
    å›è»¢ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®ç”»åƒã«ã™ã¹ã¦æç”»ã€‚
    ãƒ»è–„ã„ãƒ¡ãƒƒã‚·ãƒ¥
    ãƒ»ç·‘ï¼šå®Ÿæ¸¬ã®é¡”å¤–æ¥æ 
    ãƒ»èµ¤/é’ï¼šç†æƒ³ã®ç¸¦æ¨ªæ¯”æ ï¼ˆé»„é‡‘/ç™½éŠ€ï¼‰
    ãƒ»ã€Œçœ‰ â†” é¼»ä¸‹ã€åŒºé–“ã®ä¸‰åˆ†å‰²ï¼šç†æƒ³ï¼ˆç ´ç·šï¼‰ï¼‹ç«¯ãƒ©ã‚¤ãƒ³ï¼ˆå®Ÿç·šï¼‰
    """
    out = crop.copy()
    h, w, _ = out.shape

    # ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆè–„ãï¼‰
    nl = mp_landmark.NormalizedLandmarkList(
        landmark=[mp_landmark.NormalizedLandmark(x=float(x)/w, y=float(y)/h) for (x,y) in xy]
    )
    mp_draw.draw_landmarks(
        out, nl, mp_face.FACEMESH_TESSELATION,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_draw.DrawingSpec(color=(210,210,210), thickness=1, circle_radius=0)
    )

    # é¡”å®Ÿæ¸¬æ ï¼ˆç·‘ï¼‰
    oval = face_oval_indices()
    pts = xy[oval]
    x1, y1 = pts[:,0].min(), pts[:,1].min()
    x2, y2 = pts[:,0].max(), pts[:,1].max()
    x1i, y1i, x2i, y2i = int(x1), int(y1), int(x2), int(y2)
    cv2.rectangle(out, (x1i,y1i), (x2i,y2i), (0,255,0), 2, lineType=cv2.LINE_AA)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ ï¼ˆé»„é‡‘/ç™½éŠ€ï¼‰
    width = x2i - x1i
    cx = (x1i + x2i)//2
    target_h = int(width * target_ratio)
    ymid = (y1i + y2i)//2
    ty1 = max(0, ymid - target_h//2)
    ty2 = min(h-1, ymid + target_h//2)
    tx1 = max(0, cx - width//2)
    tx2 = min(w-1, cx + width//2)
    color = (0,0,255) if label=="SILVER" else (255,0,0)
    cv2.rectangle(out, (tx1,ty1), (tx2,ty2), color, 2, lineType=cv2.LINE_AA)

    # çœ‰ â†” é¼»ä¸‹ ã®ä¸‰åˆ†å‰²
    brow_y = int((xy[IDX["BROW_R_UP"]][1] + xy[IDX["BROW_L_UP"]][1]) / 2.0)
    nose_base_y = int((xy[IDX["NOSE_L"]][1] + xy[IDX["NOSE_R"]][1]) / 2.0)
    topY, botY = min(brow_y, nose_base_y), max(brow_y, nose_base_y)
    seg_h = botY - topY

    # ç†æƒ³ï¼ˆ1/3ç­‰åˆ†ï¼‰â€¦ç ´ç·šï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆè‰²ï¼‰
    if seg_h > 4:
        for i in (1,2):
            y = int(topY + (seg_h/3)*i)
            dashed_line(out, (x1i, y), (x2i, y), color, thickness=2, dash=16, gap=10)

    # å®Ÿæ¸¬ç«¯ãƒ©ã‚¤ãƒ³ï¼ˆçœ‰ãƒ»é¼»ä¸‹ï¼‰â€¦å®Ÿç·šï¼ˆç·‘ï¼‰
    cv2.line(out, (x1i, brow_y),      (x2i, brow_y),      (0,255,0), 2, lineType=cv2.LINE_AA)
    cv2.line(out, (x1i, nose_base_y), (x2i, nose_base_y), (0,255,0), 2, lineType=cv2.LINE_AA)

    # ãƒ©ãƒ™ãƒ«
    tag = "ç™½éŠ€æ¯” âˆš2" if label=="SILVER" else "é»„é‡‘æ¯” Ï†"
    cv2.rectangle(out, (tx1, max(0,ty1-28)), (tx1+140, max(0,ty1-4)), color, -1)
    cv2.putText(out, tag, (tx1+6, max(0,ty1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)

    return out

# -------------------- ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ --------------------
def build_table(metrics: Dict[str,float], target_ratio: float, target_name: str) -> pd.DataFrame:
    # é¡” H/W ã¨ç†æƒ³ã®å·®
    face_ar = metrics["face_AR"]
    err_ar = (face_ar - target_ratio) / target_ratio * 100 if np.isfinite(face_ar) else np.nan

    # ä¸‰åˆ†å‰²ï¼ˆçœ‰â†”é¼»ä¸‹ï¼‰ï¼šç†æƒ³ã¯å„ 1/3
    # ç¾æ®µéšã§ã¯ä¸­é–“ç·šã®â€œå®Ÿæ¸¬ç‚¹â€ãŒãªã„ãŸã‚ã€å†™çœŸå€¤ã¯åŒºé–“ã‚’3ç­‰åˆ†ã¨ã¿ãªã™ï¼ˆ= 1/3ï¼‰ã€‚
    # å°†æ¥çš„ã«ä¸­é–“è§£å‰–ç‚¹ï¼ˆä¾‹ï¼šç›®ä¸­å¿ƒåˆ—/ä¸Šå£å”‡ç‚¹ ç­‰ï¼‰ã‚’æ¡ç”¨ã™ã‚Œã°ç½®æ›å¯èƒ½ã€‚
    thirds_photo = [1/3, 1/3, 1/3]
    thirds_err = [0.0, 0.0, 0.0]

    rows = [
        {"é …ç›®":"é¡”ã®ç¸¦/æ¨ª (H/W)", "å†™çœŸå€¤":round(face_ar,3) if np.isfinite(face_ar) else None,
         "ç†æƒ³å€¤":f"{target_name}={round(target_ratio,3)}", "å·®åˆ†%":round(err_ar,2) if np.isfinite(err_ar) else None},
        {"é …ç›®":"ä¸Šæ®µï¼ˆçœ‰â†’1/3ï¼‰/ åŒºé–“(çœ‰â†”é¼»ä¸‹)", "å†™çœŸå€¤":round(thirds_photo[0],3), "ç†æƒ³å€¤":"1/3", "å·®åˆ†%":round(thirds_err[0],2)},
        {"é …ç›®":"ä¸­æ®µï¼ˆ1/3â†’2/3ï¼‰/ åŒºé–“(çœ‰â†”é¼»ä¸‹)", "å†™çœŸå€¤":round(thirds_photo[1],3), "ç†æƒ³å€¤":"1/3", "å·®åˆ†%":round(thirds_err[1],2)},
        {"é …ç›®":"ä¸‹æ®µï¼ˆ2/3â†’é¼»ä¸‹ï¼‰/ åŒºé–“(çœ‰â†”é¼»ä¸‹)", "å†™çœŸå€¤":round(thirds_photo[2],3), "ç†æƒ³å€¤":"1/3", "å·®åˆ†%":round(thirds_err[2],2)},
        {"é …ç›®":"ç›®é–“éš”/ç‰‡ç›®å¹…", "å†™çœŸå€¤":round(metrics["eye_spacing_ratio"],3) if np.isfinite(metrics["eye_spacing_ratio"]) else None,
         "ç†æƒ³å€¤":"å‚è€ƒ: â‰ˆ1.0", "å·®åˆ†%":None},
        {"é …ç›®":"é¼»å¹…/å£å¹…", "å†™çœŸå€¤":round(metrics["nose_to_mouth"],3) if np.isfinite(metrics["nose_to_mouth"]) else None,
         "ç†æƒ³å€¤":"å‚è€ƒ: å€‹äººå·®", "å·®åˆ†%":None},
    ]
    return pd.DataFrame(rows)

# -------------------- UI æœ¬ä½“ --------------------
uploaded = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆJPG/PNGï¼‰", type=["jpg","jpeg","png"])
if not uploaded:
    st.stop()

img = Image.open(uploaded).convert("RGB")
np_img = pil2np(img)

# å¤§ãã™ãã‚‹ç”»åƒã¯å…ˆã«ç¸®å°ï¼ˆå‡¦ç†è»½é‡åŒ–ï¼‰
long_edge = max(np_img.shape[:2])
if long_edge > 1600:
    scale = 1600 / long_edge
    np_img = cv2.resize(np_img, (int(np_img.shape[1]*scale), int(np_img.shape[0]*scale)))

# é¡”æ¤œå‡º
res = face_mesh.process(np_img)
if not res.multi_face_landmarks:
    st.error("é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆæ­£é¢ã«è¿‘ã„ãƒ»æ˜ã‚‹ã„ç”»åƒã§ãŠè©¦ã—ãã ã•ã„ï¼‰ã€‚")
    st.stop()

landmarks = res.multi_face_landmarks[0].landmark
h, w, _ = np_img.shape
xy = landmarks_to_xy(landmarks, w, h)

# å›è»¢è£œæ­£ & é¡”ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆã“ã“ã¾ã§ã¯æç”»ã—ãªã„ï¼‰
crop, xy_crop = align_and_crop(np_img, xy, margin=0.18)

# æŒ‡æ¨™
metrics = compute_metrics(xy_crop)

# é»„é‡‘æ¯” / ç™½éŠ€æ¯”ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’å…ˆã«2æšä½œã£ã¦ãŠã
img_golden = build_overlay(crop, xy_crop, PHI, "GOLDEN")
img_silver = build_overlay(crop, xy_crop, SILVER, "SILVER")

# åˆ‡æ›¿UIï¼ˆç”»åƒã¨è¡¨ãŒåŒæœŸã—ã¦åˆ‡ã‚Šæ›¿ã‚ã‚‹ï¼‰
mode = st.segmented_control("æ¯”è¼ƒå¯¾è±¡", options=["é»„é‡‘æ¯”", "ç™½éŠ€æ¯”"], default="é»„é‡‘æ¯”")
if mode == "é»„é‡‘æ¯”":
    target_ratio, target_name, show_img = PHI, "Ï†", img_golden
else:
    target_ratio, target_name, show_img = SILVER, "âˆš2", img_silver

st.subheader("çµæœã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆå›è»¢è£œæ­£ & é¡”ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã«æç”»ï¼‰")
st.image(Image.fromarray(show_img), use_container_width=True)

st.subheader("æ¯”ç‡ã®æ¯”è¼ƒè¡¨")
df = build_table(metrics, target_ratio, target_name)
st.dataframe(df, use_container_width=True)

st.caption(
    "ä¸‰åˆ†å‰²ã¯ã€Œçœ‰ â†” é¼»ä¸‹ã€ã®åŒºé–“ã‚’ 1/3 ç­‰åˆ†ã¨ã™ã‚‹ç†æƒ³ç·šï¼ˆç ´ç·šï¼‰ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    "å°†æ¥çš„ã«ä¸­é–“è§£å‰–ç‚¹ï¼ˆä¾‹ï¼šç›®ä¸­å¿ƒåˆ—ã‚„ä¸Šå£å”‡ç‚¹ï¼‰ã‚’ç”¨ã„ã‚Œã° â€œå®Ÿæ¸¬ã®ä¸‰åˆ†ç‚¹â€ ã«ã‚ˆã‚‹è©•ä¾¡ã¸æ‹¡å¼µã§ãã¾ã™ã€‚"
)
