import math
from typing import Dict, Tuple, List

import cv2
import numpy as np
import streamlit as st
from PIL import Image
import mediapipe as mp
from mediapipe.framework.formats import landmark_pb2 as mp_landmark
import pandas as pd

# ================= ãƒšãƒ¼ã‚¸è¨­å®š & UIæœ€å°åŒ– =================
st.set_page_config(page_title="é¡” Ã— é»„é‡‘æ¯”/ç™½éŠ€æ¯”ï¼ˆä¸‰åˆ†å‰²ï¼‰", page_icon="ğŸ“", layout="centered")
st.markdown("<style>#MainMenu,header,footer{visibility:hidden;}</style>", unsafe_allow_html=True)
st.title("ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º Ã— é»„é‡‘æ¯” / ç™½éŠ€æ¯”ï¼ˆçœ‰â†”é¼»ä¸‹ã‚’åŸºæº–ã«ä¸‰åˆ†å‰²ï¼‰")

# ================= MediaPipeï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ =================
@st.cache_resource
def get_facemesh():
    return mp.solutions.face_mesh.FaceMesh(
        static_image_mode=True,
        refine_landmarks=True,
        max_num_faces=1,
        min_detection_confidence=0.3
    )

mp_face = mp.solutions.face_mesh
mp_draw = mp.solutions.drawing_utils
face_mesh = get_facemesh()

# ================= å®šæ•°ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =================
PHI = (1 + 5 ** 0.5) / 2.0      # 1.618...
SILVER = 2 ** 0.5               # 1.414...

# ã‚ˆãä½¿ã†ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ index
IDX = dict(
    R_E_OUT=33, R_E_IN=133, L_E_IN=362, L_E_OUT=263,  # ç›®
    M_R=61, M_L=291,                                  # å£è§’
    NOSE_L=97, NOSE_R=326,                            # é¼»ç¿¼ç«¯ï¼ˆé¼»ä¸‹è¿‘ä¼¼ã«åˆ©ç”¨ï¼‰
    CHIN=152,                                         # é¡å…ˆ
    BROW_R_UP=105, BROW_L_UP=334                      # çœ‰ä¸Šã®ä»£è¡¨ç‚¹
)

def pil2np(img: Image.Image) -> np.ndarray:
    return np.array(img.convert("RGB"))

def dist(p1, p2) -> float:
    return float(np.linalg.norm(np.array(p1) - np.array(p2)))

def landmarks_to_xy(landmarks, w: int, h: int) -> np.ndarray:
    return np.array([(lm.x * w, lm.y * h) for lm in landmarks], dtype=np.float32)

def face_oval_indices() -> List[int]:
    return sorted({i for pair in mp_face.FACEMESH_FACE_OVAL for i in pair})

def dashed_line(img, pt1, pt2, color, thickness=2, dash=12, gap=8):
    """OpenCV ã§ç ´ç·šï¼ˆã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹ä»˜ãï¼‰"""
    p1 = np.array(pt1, dtype=float); p2 = np.array(pt2, dtype=float)
    length = np.linalg.norm(p2 - p1)
    if length < 1: return
    v = (p2 - p1) / length
    n = int(length // (dash + gap)) + 1
    for i in range(n):
        s = p1 + (dash + gap) * i * v
        e = p1 + ((dash + gap) * i + dash) * v
        cv2.line(img, tuple(s.astype(int)), tuple(e.astype(int)), color, thickness, lineType=cv2.LINE_AA)

# ================= æ•´åˆ—ï¼ˆç›®ã®æ°´å¹³åŒ–ï¼‰& åˆ‡ã‚Šå‡ºã— =================
def align_rotate(img_rgb: np.ndarray, xy: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """ç›®ã®ä¸­å¿ƒç·šãŒæ°´å¹³ã«ãªã‚‹ã‚ˆã†å›è»¢ã€‚ç”»åƒã¨ç‚¹ç¾¤ã‚’å›è»¢ã€‚"""
    h, w, _ = img_rgb.shape
    re_c = (xy[IDX["R_E_OUT"]] + xy[IDX["R_E_IN"]]) / 2.0
    le_c = (xy[IDX["L_E_OUT"]] + xy[IDX["L_E_IN"]]) / 2.0
    dy, dx = (le_c[1] - re_c[1]), (le_c[0] - re_c[0])
    angle = math.degrees(math.atan2(dy, dx))
    center = (w/2.0, h/2.0)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)

    rot = cv2.warpAffine(img_rgb, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
    ones = np.ones((xy.shape[0], 1))
    xy_h = np.hstack([xy, ones])
    xy_rot = (M @ xy_h.T).T
    return rot, xy_rot

def compute_keylines_from_rotated(xy_rot: np.ndarray) -> Dict[str, float]:
    """å›è»¢å¾Œã®åº§æ¨™ã‹ã‚‰ã€ä¸‰åˆ†å‰²ç”¨ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ y ã‚’ç®—å‡ºã€‚"""
    brow_y = (xy_rot[IDX["BROW_R_UP"]][1] + xy_rot[IDX["BROW_L_UP"]][1]) / 2.0
    nose_base_y = (xy_rot[IDX["NOSE_L"]][1] + xy_rot[IDX["NOSE_R"]][1]) / 2.0
    chin_y = xy_rot[IDX["CHIN"]][1]
    oval = face_oval_indices()
    hairline_y = float(np.min(xy_rot[oval][:, 1]))  # ç”Ÿãˆéš›è¿‘ä¼¼ï¼šå¤–è¼ªéƒ­ã®æœ€ä¸Š
    return dict(brow_y=brow_y, nose_base_y=nose_base_y, chin_y=chin_y, hairline_y=hairline_y)

def compute_crop_box(xy_rot: np.ndarray, img_shape, key: Dict[str, float], extra_margin=0.18) -> Tuple[int,int,int,int]:
    """é¡”å¤–è¼ªéƒ­ã¨â€œç†æƒ³ç·šï¼ˆç”Ÿãˆéš›=çœ‰-1, é¡=é¼»ä¸‹+1ï¼‰â€ãŒå…¥ã‚‹ã‚ˆã†ã«ãƒˆãƒªãƒŸãƒ³ã‚°ç¯„å›²ã‚’æ±ºå®šã€‚"""
    h, w = img_shape[:2]
    oval = face_oval_indices()
    pts = xy_rot[oval]
    x1, y1 = float(np.min(pts[:,0])), float(np.min(pts[:,1]))
    x2, y2 = float(np.max(pts[:,0])), float(np.max(pts[:,1]))

    base = key["nose_base_y"] - key["brow_y"]      # çœ‰â†’é¼»ä¸‹ï¼ˆåŸºæº–=1ï¼‰
    ideal_top = key["brow_y"] - base               # ç†æƒ³ã®ç”Ÿãˆéš›ãƒ©ã‚¤ãƒ³
    ideal_bottom = key["nose_base_y"] + base       # ç†æƒ³ã®é¡å…ˆãƒ©ã‚¤ãƒ³

    y1 = min(y1, ideal_top)
    y2 = max(y2, ideal_bottom)

    bw, bh = (x2 - x1), (y2 - y1)
    x1 -= bw * extra_margin; x2 += bw * extra_margin
    y1 -= bh * extra_margin; y2 += bh * extra_margin

    x1i = int(max(0, round(x1))); y1i = int(max(0, round(y1)))
    x2i = int(min(w-1, round(x2))); y2i = int(min(h-1, round(y2)))
    return x1i, y1i, x2i, y2i

def crop_with_box(img_rot: np.ndarray, xy_rot: np.ndarray, box: Tuple[int,int,int,int]) -> Tuple[np.ndarray, np.ndarray]:
    x1,y1,x2,y2 = box
    crop = img_rot[y1:y2, x1:x2].copy()
    xy_crop = xy_rot.copy()
    xy_crop[:,0] -= x1; xy_crop[:,1] -= y1
    return crop, xy_crop

# ================= æŒ‡æ¨™ï¼ˆåˆ‡ã‚Šå‡ºã—å¾Œã«è¨ˆç®—ï¼‰ =================
def compute_metrics_on_crop(xy: np.ndarray) -> Dict[str, float]:
    oval = face_oval_indices()
    pts = xy[oval]
    left = tuple(pts[pts[:,0].argmin()])
    right = tuple(pts[pts[:,0].argmax()])
    top = tuple(pts[pts[:,1].argmin()])
    bottom = tuple(pts[pts[:,1].argmax()])
    face_w = dist(left, right); face_h = dist(top, bottom)
    face_AR = face_h / face_w if face_w > 1e-6 else np.nan

    brow_y = (xy[IDX["BROW_R_UP"]][1] + xy[IDX["BROW_L_UP"]][1]) / 2.0
    nose_base_y = (xy[IDX["NOSE_L"]][1] + xy[IDX["NOSE_R"]][1]) / 2.0
    chin_y = xy[IDX["CHIN"]][1]
    hairline_y = float(np.min(pts[:,1]))

    L_top = brow_y - hairline_y
    L_mid = nose_base_y - brow_y
    L_bot = chin_y - nose_base_y

    re_w = dist(xy[IDX["R_E_OUT"]], xy[IDX["R_E_IN"]])
    le_w = dist(xy[IDX["L_E_OUT"]], xy[IDX["L_E_IN"]])
    eye_w = (re_w + le_w) / 2.0
    re_c = (xy[IDX["R_E_OUT"]] + xy[IDX["R_E_IN"]]) / 2.0
    le_c = (xy[IDX["L_E_OUT"]] + xy[IDX["L_E_IN"]]) / 2.0
    interocular = dist(re_c, le_c)
    eye_spacing_ratio = interocular / eye_w if eye_w>1e-6 else np.nan  # ç†æƒ³=1

    nose_w = dist(xy[IDX["NOSE_L"]], xy[IDX["NOSE_R"]])
    mouth_w = dist(xy[IDX["M_R"]], xy[IDX["M_L"]])
    nose_to_mouth = nose_w / mouth_w if mouth_w>1e-6 else np.nan

    return dict(
        face_w=face_w, face_h=face_h, face_AR=face_AR,
        hairline_y=hairline_y, brow_y=brow_y, nose_base_y=nose_base_y, chin_y=chin_y,
        L_top=L_top, L_mid=L_mid, L_bot=L_bot,
        eye_spacing_ratio=eye_spacing_ratio, nose_to_mouth=nose_to_mouth
    )

# ================= ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆæç”»ã¯ã™ã¹ã¦ã‚¯ãƒ­ãƒƒãƒ—å¾Œï¼‰ =================
def build_overlay(crop: np.ndarray, xy: np.ndarray, target_ratio: float, label: str) -> np.ndarray:
    """é»„é‡‘/ç™½éŠ€ã®æ  + ä¸‰åˆ†å‰²ï¼ˆç†æƒ³1:1:1 & å®Ÿæ¸¬ç«¯ï¼‰ã‚’æç”»ã€‚ã™ã¹ã¦ AA ã§æãã€‚"""
    out = crop.copy()
    h, w, _ = out.shape

    # ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆè–„ãï¼‰
    nl = mp_landmark.NormalizedLandmarkList(
        landmark=[mp_landmark.NormalizedLandmark(x=float(x)/w, y=float(y)/h) for (x,y) in xy]
    )
    mp_draw.draw_landmarks(
        out, nl, mp_face.FACEMESH_TESSELATION,
        landmark_drawing_spec=None,
        connection_drawing_spec=mp_draw.DrawingSpec(color=(210,210,210), thickness=1, circle_radius=0)
    )

    # é¡”å¤–æ¥æ ï¼ˆç·‘ï¼‰
    oval = face_oval_indices()
    pts = xy[oval]
    x1, y1 = int(np.min(pts[:,0])), int(np.min(pts[:,1]))
    x2, y2 = int(np.max(pts[:,0])), int(np.max(pts[:,1]))
    cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2, lineType=cv2.LINE_AA)

    # é»„é‡‘/ç™½éŠ€ã®æ ï¼ˆä¸­å¤®åˆã‚ã›ï¼‰ï¼šå¹…Ã—æ¯”ç‡
    width = x2 - x1
    cx = (x1 + x2)//2
    t_h = int(width * target_ratio)
    ymid = (y1 + y2)//2
    ty1 = max(0, ymid - t_h//2)
    ty2 = min(h-1, ymid + t_h//2)
    tx1 = max(0, cx - width//2)
    tx2 = min(w-1, cx + width//2)
    col = (0,0,255) if label=="SILVER" else (255,0,0)
    cv2.rectangle(out, (tx1,ty1), (tx2,ty2), col, 2, lineType=cv2.LINE_AA)

    # â€”â€” ä¸‰åˆ†å‰²ï¼šçœ‰â†”é¼»ä¸‹ ã‚’ 1 ã¨ã—ã¦ 1:1:1 ã®ç†æƒ³ç·š + å®Ÿæ¸¬ç«¯ â€”â€” #
    brow_y = int((xy[IDX["BROW_R_UP"]][1] + xy[IDX["BROW_L_UP"]][1]) / 2.0)
    nose_y = int((xy[IDX["NOSE_L"]][1] + xy[IDX["NOSE_R"]][1]) / 2.0)
    base = max(1, nose_y - brow_y)

    ideal_hair = int(brow_y - base)  # ç”Ÿãˆéš› = çœ‰ - 1
    ideal_chin = int(nose_y + base)  # é¡å…ˆ = é¼»ä¸‹ + 1

    # ç†æƒ³ï¼ˆç ´ç·šï¼šã‚¿ãƒ¼ã‚²ãƒƒãƒˆè‰²ï¼‰
    dashed_line(out, (x1, ideal_hair), (x2, ideal_hair), col, thickness=3, dash=18, gap=12)
    dashed_line(out, (x1, ideal_chin), (x2, ideal_chin), col, thickness=3, dash=18, gap=12)

    # å®Ÿæ¸¬ç«¯ï¼šç”Ÿãˆéš›ï¼ˆå¤–è¼ªéƒ­æœ€ä¸Šï¼‰ã¨é¡å…ˆï¼ˆç·‘ã®å®Ÿç·šï¼‰
    hairline = int(np.min(pts[:,1]))
    chin = int(xy[IDX["CHIN"]][1])
    cv2.line(out, (x1, hairline), (x2, hairline), (0,255,0), 3, lineType=cv2.LINE_AA)
    cv2.line(out, (x1, chin), (x2, chin), (0,255,0), 3, lineType=cv2.LINE_AA)

    # çœ‰ã¨é¼»ä¸‹ï¼ˆç·‘ã®å®Ÿç·šï¼‰
    cv2.line(out, (x1, brow_y), (x2, brow_y), (0,255,0), 3, lineType=cv2.LINE_AA)
    cv2.line(out, (x1, nose_y), (x2, nose_y), (0,255,0), 3, lineType=cv2.LINE_AA)

    # ãƒ©ãƒ™ãƒ«
    tag = "ç™½éŠ€æ¯” âˆš2" if label=="SILVER" else "é»„é‡‘æ¯” Ï†"
    cv2.rectangle(out, (tx1, max(0,ty1-30)), (tx1+150, max(0,ty1-6)), col, -1)
    cv2.putText(out, tag, (tx1+6, max(0,ty1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)

    return out

# ================= ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ¯”ç‡ï¼‰ =================
def build_table(metrics: Dict[str,float], target_ratio: float, target_name: str) -> pd.DataFrame:
    # é¡” H/W ã¨ Ï†/âˆš2 ã®èª¤å·®
    face_ar = metrics["face_AR"]
    err_ar = (face_ar - target_ratio) / target_ratio * 100 if np.isfinite(face_ar) else np.nan

    # ä¸‰åˆ†å‰²ï¼ˆç”Ÿãˆéš›â†’çœ‰ / çœ‰â†’é¼»ä¸‹ / é¼»ä¸‹â†’é¡å…ˆï¼‰ã‚’ (çœ‰â†’é¼»ä¸‹) ã§æ­£è¦åŒ–
    L_top, L_mid, L_bot = metrics["L_top"], metrics["L_mid"], metrics["L_bot"]
    if L_mid and L_mid > 1e-6:
        r_top = float(L_top / L_mid)
        r_mid = 1.0
        r_bot = float(L_bot / L_mid)
        e_top = (r_top - 1.0) * 100
        e_mid = 0.0
        e_bot = (r_bot - 1.0) * 100
    else:
        r_top = r_mid = r_bot = e_top = e_mid = e_bot = np.nan

    # ç›®é–“éš”/ç‰‡ç›®å¹…ï¼ˆç†æƒ³=1ï¼‰
    eye_ratio = metrics["eye_spacing_ratio"]
    eye_err = (eye_ratio - 1.0) * 100 if np.isfinite(eye_ratio) else np.nan

    # é¼»å¹…/å£å¹…ï¼ˆå‚è€ƒï¼‰
    nose_to_mouth = metrics["nose_to_mouth"]

    rows = [
        {"é …ç›®":"é¡”ã®ç¸¦/æ¨ª (H/W)", "å†™çœŸå€¤":round(face_ar,3) if np.isfinite(face_ar) else None,
         "ç†æƒ³å€¤":f"{target_name}={round(target_ratio,3)}", "å·®åˆ†%":round(err_ar,2) if np.isfinite(err_ar) else None},
        {"é …ç›®":"(ç”Ÿãˆéš›â†’çœ‰) / (çœ‰â†’é¼»ä¸‹)", "å†™çœŸå€¤":round(r_top,3) if np.isfinite(r_top) else None,
         "ç†æƒ³å€¤":"1", "å·®åˆ†%":round(e_top,2) if np.isfinite(e_top) else None},
        {"é …ç›®":"(çœ‰â†’é¼»ä¸‹) / (çœ‰â†’é¼»ä¸‹)", "å†™çœŸå€¤":round(r_mid,3) if np.isfinite(r_mid) else None,
         "ç†æƒ³å€¤":"1", "å·®åˆ†%":round(e_mid,2) if np.isfinite(e_mid) else None},
        {"é …ç›®":"(é¼»ä¸‹â†’é¡å…ˆ) / (çœ‰â†’é¼»ä¸‹)", "å†™çœŸå€¤":round(r_bot,3) if np.isfinite(r_bot) else None,
         "ç†æƒ³å€¤":"1", "å·®åˆ†%":round(e_bot,2) if np.isfinite(e_bot) else None},
        {"é …ç›®":"ç›®é–“éš”/ç‰‡ç›®å¹…", "å†™çœŸå€¤":round(eye_ratio,3) if np.isfinite(eye_ratio) else None,
         "ç†æƒ³å€¤":"1", "å·®åˆ†%":round(eye_err,2) if np.isfinite(eye_err) else None},
        {"é …ç›®":"é¼»å¹…/å£å¹…", "å†™çœŸå€¤":round(nose_to_mouth,3) if np.isfinite(nose_to_mouth) else None,
         "ç†æƒ³å€¤":"å‚è€ƒ", "å·®åˆ†%":None},
    ]
    return pd.DataFrame(rows)

# ================= ã‚¢ãƒ—ãƒªæœ¬ä½“ =================
uploaded = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆJPG/PNGï¼‰", type=["jpg","jpeg","png"])
if not uploaded:
    st.stop()

img = Image.open(uploaded).convert("RGB")
np_img = pil2np(img)

# å‡¦ç†è² è·ã¨è¦‹ãŸç›®ã®ãƒãƒ©ãƒ³ã‚¹ã§ã€å…ƒç”»åƒãŒå¤§ãã™ãã‚‹å ´åˆã¯å…ˆã«ç¸®å°
long_edge = max(np_img.shape[:2])
if long_edge > 1800:
    scale0 = 1800 / long_edge
    np_img = cv2.resize(np_img, (int(np_img.shape[1]*scale0), int(np_img.shape[0]*scale0)), interpolation=cv2.INTER_AREA)

# FaceMesh
res = face_mesh.process(np_img)
if not res.multi_face_landmarks:
    st.error("é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ­£é¢ã«è¿‘ã„ãƒ»æ˜ã‚‹ã„ç”»åƒã§ãŠè©¦ã—ãã ã•ã„ã€‚")
    st.stop()

landmarks = res.multi_face_landmarks[0].landmark
h, w, _ = np_img.shape
xy = landmarks_to_xy(landmarks, w, h)

# 1) å›è»¢
rot_img, xy_rot = align_rotate(np_img, xy)

# 2) ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç®—å‡ºï¼ˆå›è»¢å¾Œï¼‰
keys = compute_keylines_from_rotated(xy_rot)

# 3) ã‚­ãƒ¼ã‚’å«ã‚€ã‚ˆã†ã«ãƒˆãƒªãƒŸãƒ³ã‚° â†’ åˆ‡ã‚Šå‡ºã—
box = compute_crop_box(xy_rot, rot_img.shape, keys, extra_margin=0.18)
crop, xy_crop = crop_with_box(rot_img, xy_rot, box)

# 4) è¡¨ç¤ºç”¨ã«å…ˆã«æ‹¡å¤§ï¼ˆæ‹¡å¤§å¾Œã«æç”»â†’ç­‰å€è¡¨ç¤ºã§ã‚®ã‚¶ã‚®ã‚¶é˜²æ­¢ï¼‰
TARGET_DISPLAY_WIDTH = 900  # ä»•ä¸ŠãŒã‚Šã®æ¨ªå¹…ï¼ˆå¥½ã¿ã§ï¼‰
scale_disp = TARGET_DISPLAY_WIDTH / crop.shape[1]
if scale_disp < 1.0:
    # ç¸®å°ã¯ç·šãŒç´°ããªã‚‹ã®ã§é¿ã‘ã€ç­‰å€ã§æç”»ã™ã‚‹
    scale_disp = 1.0

disp_img = cv2.resize(
    crop,
    (int(crop.shape[1] * scale_disp), int(crop.shape[0] * scale_disp)),
    interpolation=cv2.INTER_CUBIC
)
disp_xy = xy_crop * scale_disp

# 5) æŒ‡æ¨™è¨ˆç®—ï¼ˆåˆ‡ã‚Šå‡ºã—å¾Œã®åº§æ¨™ã§ï¼‰
metrics = compute_metrics_on_crop(disp_xy)

# 6) ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒï¼ˆé»„é‡‘/ç™½éŠ€ï¼‰ã‚’äº‹å‰ç”Ÿæˆ
img_golden = build_overlay(disp_img, disp_xy, PHI, "GOLDEN")
img_silver = build_overlay(disp_img, disp_xy, SILVER, "SILVER")

# 7) åˆ‡æ›¿ UIï¼ˆç”»åƒã¨è¡¨ãŒåŒæœŸï¼‰
mode = st.segmented_control("æ¯”è¼ƒå¯¾è±¡ï¼ˆç”»åƒãƒ»è¡¨ã¨ã‚‚ã«åˆ‡æ›¿ï¼‰", options=["é»„é‡‘æ¯”", "ç™½éŠ€æ¯”"], default="é»„é‡‘æ¯”")
if mode == "é»„é‡‘æ¯”":
    target_ratio, target_name, show_img = PHI, "Ï†", img_golden
else:
    target_ratio, target_name, show_img = SILVER, "âˆš2", img_silver

st.subheader("çµæœã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆå›è»¢è£œæ­£ & åˆ‡ã‚Šå‡ºã—å¾Œ / æ‹¡å¤§å¾Œã«æç”»ï¼‰")
# ç­‰å€ã§è¡¨ç¤ºï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å´ã®æ‹¡ç¸®ã‚’é¿ã‘ã‚‹ï¼‰
st.image(Image.fromarray(show_img), use_container_width=False, width=show_img.shape[1])

st.subheader("æ¯”ç‡ã®æ¯”è¼ƒè¡¨")
df = build_table(metrics, target_ratio, target_name)
st.dataframe(df, use_container_width=True)

st.caption(
    "ä¸‰åˆ†å‰²ã¯ã€ç”Ÿãˆéš›â†’çœ‰ã€ã€çœ‰â†’é¼»ä¸‹ã€ã€é¼»ä¸‹â†’é¡å…ˆã€ãŒ 1:1:1ï¼ˆçœ‰â†”é¼»ä¸‹ã‚’åŸºæº–1ï¼‰ã€‚"
    "é»„é‡‘æ¯”(1:1.618)ãƒ»ç™½éŠ€æ¯”(1:1.4)ã¯å…¨ä½“H/Wã®å‚ç…§æ¯”ã€‚"
    "æç”»ã¯ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œãƒ»æ‹¡å¤§å¾Œã«è¡Œã„ã€ã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹ã§ç·šã®ã‚®ã‚¶ã¤ãã‚’æŠ‘åˆ¶ã—ã¦ã„ã¾ã™ã€‚"
)
